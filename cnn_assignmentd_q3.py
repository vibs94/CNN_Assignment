# -*- coding: utf-8 -*-
"""CNN_Assignmentd_Q3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16GGDx1Y_MXQbbR7YIF04Eiv_CryT6Or7
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, UpSampling2D,Activation
from keras.layers.normalization import BatchNormalization
from sklearn.model_selection import train_test_split
import torch
from keras.preprocessing.image import ImageDataGenerator

# %matplotlib inline

from google.colab import drive
drive.mount('/content/gdrive')

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

"""Dataset dimensions"""

print(f'X_train: {x_train.shape}')
print(f'Y_train: {y_train.shape}')
print(f'X_test: {x_test.shape}')
print(f'Y_test: {y_test.shape}')

"""Show sample data"""

image_index = 7777
print(y_train[image_index]) 
plt.imshow(x_train[image_index], cmap='Greys')

"""Add noice"""

noise_factor = 0.25
x_train_noice = x_train + noise_factor*np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noice = x_test + noise_factor*np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)
x_train_noice = np.clip(x_train_noice, 0., 1.)
x_test_noice = np.clip(x_test_noice, 0., 1.)

print(y_train[image_index]) 
plt.imshow(x_train_noice[image_index], cmap='Greys')

"""Reshaping"""

x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)

x_train_noice = x_train_noice.reshape(x_train_noice.shape[0], 28, 28, 1)
x_test_noice = x_test_noice.reshape(x_test_noice.shape[0], 28, 28, 1)
input_shape = (28, 28, 1)

"""Normalizing"""

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255
print(f'x_train shape: {x_train.shape}')
print(f'Number of images in x_train {x_train.shape[0]}')
print(f'Number of images in x_test {x_test.shape[0]}')
print('======================================')
x_train_noice = x_train_noice.astype('float32')
x_test_noice = x_test_noice.astype('float32')
x_train_noice /= 255
x_test_noice /= 255
print(f'x_train_noice shape: {x_train_noice.shape}')
print(f'Number of images in x_train_noice {x_train_noice.shape[0]}')
print(f'Number of images in x_test_noice {x_test_noice.shape[0]}')

"""Autoencider model"""

autoencoder = Sequential()
#encode
autoencoder.add(Conv2D(28, kernel_size=(7,7), activation=tf.nn.relu, padding='same', input_shape=input_shape))
autoencoder.add(MaxPooling2D(pool_size=(2, 2)))
autoencoder.add(Dropout(0.2))
autoencoder.add(Conv2D(14, kernel_size=(7,7), activation=tf.nn.relu, padding='same'))
autoencoder.add(MaxPooling2D(pool_size=(2, 2)))
#decode
autoencoder.add(Conv2D(14, kernel_size=(7,7), activation=tf.nn.relu, padding='same'))
autoencoder.add(UpSampling2D())
autoencoder.add(Dropout(0.2))
autoencoder.add(Conv2D(28, kernel_size=(7,7), activation=tf.nn.relu, padding='same'))
autoencoder.add(UpSampling2D())
autoencoder.add(Conv2D(1, kernel_size=(7,7), activation=tf.nn.sigmoid, padding='same'))

"""Compile autoencoder"""

autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

autoencoder.summary()

"""Denoising"""

X_noise_train, X_noise_valid, X_train, X_valid = train_test_split(x_train_noice, x_train, test_size=0.5, random_state=42, shuffle=True)

history = autoencoder.fit(X_noise_train, X_train,
                epochs=25,
                shuffle=True,
                validation_data=(X_noise_valid, X_valid)
               )
#save model
model_save_name = 'autoencoder.pt'
path = F"/content/gdrive/My Drive/{model_save_name}" 
autoencoder.save(path)

#Visualize autoencoder results
# Defining Figure
f = plt.figure(figsize=(10,7))
f.add_subplot()

#Adding Subplot
plt.plot(history.epoch, history.history['loss'], label = "loss") # Loss curve for training set
plt.plot(history.epoch, history.history['val_loss'], label = "val_loss") # Loss curve for validation set

plt.title("Loss Curve",fontsize=18)
plt.xlabel("Epochs",fontsize=15)
plt.ylabel("Loss",fontsize=15)
plt.grid(alpha=0.3)
plt.legend()
plt.savefig("Loss_curve.png")
plt.show()

autoencoder1 = tf.keras.models.load_model(path)
x_train_noice = autoencoder.predict(x_train_noice)
x_test_noice = autoencoder.predict(x_test_noice)

print(y_train[image_index]) 
plt.imshow(x_train_noice[image_index].reshape([28, 28]), cmap='Greys')

"""Model"""

model = Sequential()
model.add(Conv2D(28, kernel_size=(7,7), activation=tf.nn.relu, input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(28, kernel_size=(3,3), activation=tf.nn.relu))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation=tf.nn.relu))
model.add(Dropout(0.2))
model.add(Dense(10,activation=tf.nn.softmax))

"""Compiling model"""

model.compile(optimizer='adam', 
              loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])
image_classifier_history = model.fit(x=x_train_noice,y=y_train, epochs=10)

"""Visualize image classifier results"""

# Defining Figure
f = plt.figure(figsize=(10,7))
f.add_subplot()

#Adding Subplot
plt.plot(image_classifier_history.epoch, image_classifier_history.history['loss'], label = "loss") # Loss curve for training set
plt.plot(image_classifier_history.epoch, image_classifier_history.history['accuracy'], label = "accuracy") # Loss curve for validation set

plt.title("Loss Curve",fontsize=18)
plt.xlabel("Epochs",fontsize=15)
plt.ylabel("Loss",fontsize=15)
plt.grid(alpha=0.3)
plt.legend()
plt.savefig("Loss_curve.png")
plt.show()

"""Evaluate model"""

score = model.evaluate(x_test_noice, y_test)
print(f'Test score: {score[0]}')
print(f'Test accuracy: {score[1]}')

"""Visualize results"""

predicted_classes = model.predict_classes(x_test)

correct_indices = np.nonzero(predicted_classes == y_test)[0]

incorrect_indices = np.nonzero(predicted_classes != y_test)[0]

"""Correct results"""

plt.figure()
for i, correct in enumerate(correct_indices[:9]):
    plt.subplot(3,3,i+1)
    plt.imshow(x_test[correct].reshape(28,28), cmap='gray', interpolation='none')
    plt.title("Predicted {}, Class {}".format(predicted_classes[correct], y_test[correct]))
    
plt.tight_layout()

"""Incorrect results"""

plt.figure()
for i, incorrect in enumerate(incorrect_indices[:9]):
    plt.subplot(3,3,i+1)
    plt.imshow(x_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')
    plt.title("Predicted {}, Class {}".format(predicted_classes[incorrect], y_test[incorrect]))
    
plt.tight_layout()